# Copyright 2026 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Parallel Streamlit Demo for PaperVizAgent
Accepts user text input, duplicates it 10 times, and runs parallel processing
to generate multiple diagram candidates for comparison.
"""

import streamlit as st
import asyncio
import base64
import json
from io import BytesIO
from PIL import Image
from pathlib import Path
import sys
import os
from datetime import datetime

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

print("DEBUG: Importing agents...")
try:
    from agents.planner_agent import PlannerAgent
    print("DEBUG: Imported PlannerAgent")
    from agents.visualizer_agent import VisualizerAgent
    from agents.stylist_agent import StylistAgent
    from agents.critic_agent import CriticAgent
    from agents.retriever_agent import RetrieverAgent
    from agents.vanilla_agent import VanillaAgent
    from agents.polish_agent import PolishAgent
    print("DEBUG: Imported all agents")
    from utils import config
    from utils.paperviz_processor import PaperVizProcessor
    print("DEBUG: Imported utils")

    import yaml
    config_path = Path(__file__).parent / "configs" / "model_config.yaml"
    model_config_data = {}
    if config_path.exists():
        with open(config_path, "r", encoding="utf-8") as f:
            model_config_data = yaml.safe_load(f) or {}

    def get_config_val(section, key, env_var, default=""):
        val = os.getenv(env_var)
        if not val and section in model_config_data:
            val = model_config_data[section].get(key)
        return val or default

except ImportError as e:
    print(f"DEBUG: ImportError: {e}")
    import traceback
    traceback.print_exc()
    raise e
except Exception as e:
    print(f"DEBUG: Exception during import: {e}")
    import traceback
    traceback.print_exc()
    raise e

st.set_page_config(
    layout="wide",
    page_title="PaperBanana ë°ëª¨",
    page_icon="ğŸŒ"
)

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'api_configured' not in st.session_state:
        st.session_state.api_configured = False
    if 'google_api_key' not in st.session_state:
        st.session_state.google_api_key = ""
    if 'model_name' not in st.session_state:
        st.session_state.model_name = ""
    if 'image_model_name' not in st.session_state:
        st.session_state.image_model_name = ""

@st.dialog("ğŸ” API ì„¤ì •")
def render_api_settings_dialog():
    """API ì„¤ì • ë‹¤ì´ì–¼ë¡œê·¸ ë Œë”ë§"""
    
    # ê¸°ì¡´ ì„¤ì •ê°’ ë¡œë“œ
    default_api_key = get_config_val("api_keys", "google_api_key", "GOOGLE_API_KEY", "")
    default_model = get_config_val("defaults", "model_name", "MODEL_NAME", "gemini-2.0-flash-exp")
    default_image_model = get_config_val("defaults", "image_model_name", "IMAGE_MODEL_NAME", "gemini-2.0-flash-exp-image-generation")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if not st.session_state.google_api_key and default_api_key:
        st.session_state.google_api_key = default_api_key
    if not st.session_state.model_name and default_model:
        st.session_state.model_name = default_model
    if not st.session_state.image_model_name and default_image_model:
        st.session_state.image_model_name = default_image_model
    
    # ì„¤ì • ìƒíƒœ í‘œì‹œ
    if st.session_state.api_configured or st.session_state.google_api_key:
        st.success("âœ… API ì„¤ì • ì™„ë£Œ")
    else:
        st.warning("âš ï¸ API Key ë¯¸ì„¤ì •")
    
    st.divider()
    
    # API Key ì…ë ¥
    api_key = st.text_input(
        "Google API Key",
        value=st.session_state.google_api_key,
        type="password",
        help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="AIza..."
    )
    
    # ëª¨ë¸ ì„¤ì •
    col1, col2 = st.columns(2)
    with col1:
        model_name = st.text_input(
            "í…ìŠ¤íŠ¸ ëª¨ë¸",
            value=st.session_state.model_name or "gemini-2.0-flash-exp",
            help="í…ìŠ¤íŠ¸ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ëª…"
        )
    with col2:
        image_model_name = st.text_input(
            "ì´ë¯¸ì§€ ëª¨ë¸",
            value=st.session_state.image_model_name or "gemini-2.0-flash-exp-image-generation",
            help="ì´ë¯¸ì§€ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ëª…"
        )
    
    # API Key ë°œê¸‰ ì•ˆë‚´
    with st.expander("ğŸ“– API Key ë°œê¸‰ ë°©ë²•"):
        st.markdown("""
        ### Google API Key ë°œê¸‰
        
        1. [Google AI Studio](https://aistudio.google.com/app/apikey) ì ‘ì†
        2. Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸
        3. "Create API Key" í´ë¦­
        4. ìƒˆ í”„ë¡œì íŠ¸ ì„ íƒ ë˜ëŠ” ìƒì„±
        5. API Key ë³µì‚¬í•˜ì—¬ ìœ„ì— ì…ë ¥
        
        ### ì°¸ê³  ëª¨ë¸
        - **í…ìŠ¤íŠ¸**: `gemini-2.0-flash-exp`
        - **ì´ë¯¸ì§€**: `gemini-2.0-flash-exp-image-generation`
        """)
    
    st.divider()
    
    # ë²„íŠ¼ ì˜ì—­
    col1, col2 = st.columns(2)
    
    with col1:
        # ì„¤ì • ì €ì¥ ë²„íŠ¼
        if st.button("ğŸ’¾ ì €ì¥", type="primary", use_container_width=True):
            if not api_key:
                st.error("âš ï¸ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                # ì„¸ì…˜ ìƒíƒœ ì €ì¥
                st.session_state.google_api_key = api_key
                st.session_state.model_name = model_name
                st.session_state.image_model_name = image_model_name
                st.session_state.api_configured = True
                
                # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
                os.environ["GOOGLE_API_KEY"] = api_key
                os.environ["MODEL_NAME"] = model_name
                os.environ["IMAGE_MODEL_NAME"] = image_model_name
                
                st.success("âœ… API ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
    
    with col2:
        # ì„¤ì • ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.google_api_key = ""
            st.session_state.model_name = ""
            st.session_state.image_model_name = ""
            st.session_state.api_configured = False
            st.info("ì„¤ì •ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

def render_api_settings():
    """API ì„¤ì • ë²„íŠ¼ ë° ìƒíƒœ í‘œì‹œ (í—¤ë”ìš©)"""
    # ì„¤ì • ìƒíƒœ í™•ì¸
    is_configured = st.session_state.api_configured or st.session_state.google_api_key
    
    # ë²„íŠ¼ ë ˆì´ë¸” ë° ì•„ì´ì½˜ ì„¤ì •
    if is_configured:
        button_label = "ğŸ” API ì„¤ì •"
        button_type = "secondary"
    else:
        button_label = "âš ï¸ API ì„¤ì •"
        button_type = "primary"
    
    # API ì„¤ì • ë²„íŠ¼ í´ë¦­ ì‹œ ë‹¤ì´ì–¼ë¡œê·¸ ì—´ê¸°
    if st.button(button_label, type=button_type, key="api_settings_btn"):
        render_api_settings_dialog()
    
    # í˜„ì¬ ì„¤ì •ê°’ ë°˜í™˜
    return (
        st.session_state.google_api_key,
        st.session_state.model_name or "gemini-2.0-flash-exp",
        st.session_state.image_model_name or "gemini-2.0-flash-exp-image-generation"
    )

def clean_text(text):
    """Clean text by removing invalid UTF-8 surrogate characters."""
    if not text:
        return text
    if isinstance(text, str):
        # Remove surrogate characters that cause UnicodeEncodeError
        return text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')
    return text

def base64_to_image(b64_str):
    """Convert base64 string to PIL Image."""
    if not b64_str:
        return None
    try:
        if "," in b64_str:
            b64_str = b64_str.split(",")[1]
        image_data = base64.b64decode(b64_str)
        return Image.open(BytesIO(image_data))
    except Exception:
        return None

def create_sample_inputs(method_content, caption, diagram_type="Pipeline", aspect_ratio="16:9", num_copies=10, max_critic_rounds=3):
    """Create multiple copies of the input data for parallel processing."""
    base_input = {
        "filename": "demo_input",
        "caption": caption,
        "content": method_content,
        "visual_intent": caption,
        "additional_info": {
            "rounded_ratio": aspect_ratio
        },
        "max_critic_rounds": max_critic_rounds  # Add critic rounds control
    }
    
    # Create num_copies identical inputs, each with a unique identifier
    inputs = []
    for i in range(num_copies):
        input_copy = base_input.copy()
        input_copy["filename"] = f"demo_input_candidate_{i}"
        input_copy["candidate_id"] = i
        inputs.append(input_copy)
    
    return inputs

async def process_parallel_candidates(data_list, exp_mode="dev_planner_critic", retrieval_setting="auto", model_name=""):
    """Process multiple candidates in parallel using PaperVizProcessor."""
    # Create experiment config
    exp_config = config.ExpConfig(
        dataset_name="Demo",
        split_name="demo",
        exp_mode=exp_mode,
        retrieval_setting=retrieval_setting,
        model_name=model_name,
        work_dir=Path(__file__).parent,
    )
    
    # Initialize processor with all agents
    processor = PaperVizProcessor(
        exp_config=exp_config,
        vanilla_agent=VanillaAgent(exp_config=exp_config),
        planner_agent=PlannerAgent(exp_config=exp_config),
        visualizer_agent=VisualizerAgent(exp_config=exp_config),
        stylist_agent=StylistAgent(exp_config=exp_config),
        critic_agent=CriticAgent(exp_config=exp_config),
        retriever_agent=RetrieverAgent(exp_config=exp_config),
        polish_agent=PolishAgent(exp_config=exp_config),
    )
    
    # Process all candidates in parallel (concurrency controlled by processor)
    results = []
    concurrent_num = 10  # Process all 10 in parallel
    
    async for result_data in processor.process_queries_batch(
        data_list, max_concurrent=concurrent_num, do_eval=False
    ):
        results.append(result_data)
    
    return results

async def refine_image_with_nanoviz(image_bytes, edit_prompt, aspect_ratio="21:9", image_size="2K"):
    """
    Refine an image using an Image Editing API.
    
    Args:
        image_bytes: Image data in bytes
        edit_prompt: Text description of desired changes
        aspect_ratio: Output aspect ratio (21:9, 16:9, 3:2)
        image_size: Output resolution (2K or 4K)
    
    Returns:
        Tuple of (edited_image_bytes, success_message)
    """
    try:
        from google import genai
        from google.genai import types
        
        # Initialize client with API key (not Vertex AI)
        api_key = get_config_val("api_keys", "google_api_key", "GOOGLE_API_KEY", "")
        if not api_key:
            return None, "âŒ ì˜¤ë¥˜: Google API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. configs/model_config.yamlì— ì„¤ì •í•´ì£¼ì„¸ìš”."
        
        client = genai.Client(api_key=api_key)
        
        # Prepare content
        contents = [
            types.Part.from_text(text=edit_prompt),
            types.Part.from_bytes(
                mime_type="image/jpeg",
                data=image_bytes
            )
        ]
        
        # Configure generation
        config = types.GenerateContentConfig(
            temperature=1.0,
            max_output_tokens=8192,
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(
                aspect_ratio=aspect_ratio,
                image_size=image_size,
            ),
        )
        
        # Generate refined image
        image_model = get_config_val("defaults", "image_model_name", "IMAGE_MODEL_NAME", "")
        response = await asyncio.to_thread(
            client.models.generate_content,
            model=image_model,
            contents=contents,
            config=config
        )
        
        # Extract image from response
        if response.candidates and response.candidates[0].content.parts:
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    edited_image_data = part.inline_data.data
                    
                    if isinstance(edited_image_data, bytes):
                        return edited_image_data, "âœ… ì´ë¯¸ì§€ ê°œì„  ì™„ë£Œ!"
                    elif isinstance(edited_image_data, str):
                        return base64.b64decode(edited_image_data), "âœ… ì´ë¯¸ì§€ ê°œì„  ì™„ë£Œ!"
        
        return None, "âŒ ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    except Exception as e:
        return None, f"âŒ ì˜¤ë¥˜: {str(e)}"


def get_evolution_stages(result, exp_mode):
    """Extract all evolution stages (images and descriptions) from the result."""
    task_name = "diagram"
    stages = []
    
    # Stage 1: Planner output
    planner_img_key = f"target_{task_name}_desc0_base64_jpg"
    planner_desc_key = f"target_{task_name}_desc0"
    if planner_img_key in result and result[planner_img_key]:
        stages.append({
            "name": "ğŸ“‹ ê¸°íšì(Planner)",
            "image_key": planner_img_key,
            "desc_key": planner_desc_key,
            "description": "ë°©ë²•ë¡  ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì´ˆê¸° ë„ì‹í™” ê³„íš"
        })
    
    # Stage 2: Stylist output (only for demo_full)
    if exp_mode == "demo_full":
        stylist_img_key = f"target_{task_name}_stylist_desc0_base64_jpg"
        stylist_desc_key = f"target_{task_name}_stylist_desc0"
        if stylist_img_key in result and result[stylist_img_key]:
            stages.append({
                "name": "âœ¨ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸(Stylist)",
                "image_key": stylist_img_key,
                "desc_key": stylist_desc_key,
                "description": "ìŠ¤íƒ€ì¼ì ìœ¼ë¡œ ê°œì„ ëœ ì„¤ëª…"
            })
    
    # Stage 3+: Critic iterations
    for round_idx in range(4):  # Check up to 4 rounds
        critic_img_key = f"target_{task_name}_critic_desc{round_idx}_base64_jpg"
        critic_desc_key = f"target_{task_name}_critic_desc{round_idx}"
        critic_sugg_key = f"target_{task_name}_critic_suggestions{round_idx}"
        
        if critic_img_key in result and result[critic_img_key]:
            stages.append({
                "name": f"ğŸ” í‰ê°€ì(Critic) ë¼ìš´ë“œ {round_idx}",
                "image_key": critic_img_key,
                "desc_key": critic_desc_key,
                "suggestions_key": critic_sugg_key,
                "description": f"í‰ê°€ì í”¼ë“œë°± í›„ ê°œì„  (ë°˜ë³µ {round_idx})"
            })
    
    return stages

def display_candidate_result(result, candidate_id, exp_mode):
    """ë‹¨ì¼ í›„ë³´ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    task_name = "diagram"
    
    # Determine which image to show based on exp_mode
    # For demo modes, always try to find the last critic round
    final_image_key = None
    final_desc_key = None
    
    # Try to find the last critic round
    for round_idx in range(3, -1, -1):  # Check rounds 3, 2, 1, 0
        image_key = f"target_{task_name}_critic_desc{round_idx}_base64_jpg"
        if image_key in result and result[image_key]:
            final_image_key = image_key
            final_desc_key = f"target_{task_name}_critic_desc{round_idx}"
            break
    
    # Fallback if no critic rounds completed
    if not final_image_key:
        if exp_mode == "demo_full":
            # demo_full uses stylist before visualizer
            final_image_key = f"target_{task_name}_stylist_desc0_base64_jpg"
            final_desc_key = f"target_{task_name}_stylist_desc0"
        else:
            # demo_planner_critic uses planner output
            final_image_key = f"target_{task_name}_desc0_base64_jpg"
            final_desc_key = f"target_{task_name}_desc0"
    
    # Display the final image
    if final_image_key and final_image_key in result:
        img = base64_to_image(result[final_image_key])
        if img:
            st.image(img, use_container_width=True, caption=f"í›„ë³´ {candidate_id} (ìµœì¢…)")
            
            # Add download button
            buffered = BytesIO()
            img.save(buffered, format="PNG")
            st.download_button(
                label="â¬‡ï¸ ë‹¤ìš´ë¡œë“œ",
                data=buffered.getvalue(),
                file_name=f"í›„ë³´_{candidate_id}.png",
                mime="image/png",
                key=f"download_candidate_{candidate_id}",
                use_container_width=True
            )
        else:
            st.error(f"í›„ë³´ {candidate_id}ì˜ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
    else:
        st.warning(f"í›„ë³´ {candidate_id}ì— ëŒ€í•´ ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # Show evolution timeline in an expander
    stages = get_evolution_stages(result, exp_mode)
    if len(stages) > 1:
        with st.expander(f"ğŸ”„ ê°œì„  ê³¼ì • ë³´ê¸° ({len(stages)} ë‹¨ê³„)", expanded=False):
            st.caption("íŒŒì´í”„ë¼ì¸ì˜ ê° ë‹¨ê³„ë³„ë¡œ ë„ì‹í™”ê°€ ì–´ë–»ê²Œ ê°œì„ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            
            for idx, stage in enumerate(stages):
                st.markdown(f"### {stage['name']}")
                st.caption(stage['description'])
                
                # Display the image for this stage
                stage_img = base64_to_image(result.get(stage['image_key']))
                if stage_img:
                    st.image(stage_img, use_container_width=True)
                
                # Show description
                if stage['desc_key'] in result:
                    with st.expander(f"ğŸ“ ì„¤ëª…", expanded=False):
                        cleaned_desc = clean_text(result[stage['desc_key']])
                        st.write(cleaned_desc)
                
                # Show critic suggestions if available
                if 'suggestions_key' in stage and stage['suggestions_key'] in result:
                    suggestions = result[stage['suggestions_key']]
                    with st.expander(f"ğŸ’¡ í‰ê°€ì ì œì•ˆ", expanded=False):
                        cleaned_sugg = clean_text(suggestions)
                        if cleaned_sugg.strip() == "No changes needed.":
                            st.success("âœ… ë³€ê²½ ì‚¬í•­ ì—†ìŒ - ë°˜ë³µì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.write(cleaned_sugg)
                
                # Add separator between stages (except for the last one)
                if idx < len(stages) - 1:
                    st.divider()
    else:
        # If only one stage, show description in simpler expander
        with st.expander(f"ğŸ“ ì„¤ëª… ë³´ê¸°", expanded=False):
            if final_desc_key and final_desc_key in result:
                # Clean the text to remove invalid UTF-8 characters
                cleaned_desc = clean_text(result[final_desc_key])
                st.write(cleaned_desc)
            else:
                st.info("ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤")

def main():
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    init_session_state()
    
    # í—¤ë” ì˜ì—­: ì œëª©ê³¼ API ì„¤ì • ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
    header_col1, header_col2 = st.columns([6, 1])
    
    with header_col1:
        st.title("ğŸŒ PaperBanana ë°ëª¨")
        st.markdown("AI ê¸°ë°˜ í•™ìˆ  ë„ì‹í™” ìë™ ìƒì„± ë° ê°œì„ ")
    
    with header_col2:
        st.markdown("<br>", unsafe_allow_html=True)  # ë²„íŠ¼ì„ ì•„ë˜ë¡œ ë‚´ë¦¬ê¸° ìœ„í•œ ì—¬ë°±
        # API ì„¤ì • ë²„íŠ¼ ë Œë”ë§
        api_key, model_name, image_model_name = render_api_settings()
    
    # Create tabs
    tab1, tab2 = st.tabs(["ğŸ“Š í›„ë³´ ìƒì„±", "âœ¨ ì´ë¯¸ì§€ ê°œì„ "])
    
    # ==================== TAB 1: Generate Candidates ====================
    with tab1:
        st.markdown("### ë°©ë²•ë¡  ì„¹ì…˜ê³¼ ìº¡ì…˜ì„ ì…ë ¥í•˜ì—¬ ì—¬ëŸ¬ ë„ì‹í™” í›„ë³´ë¥¼ ìƒì„±í•˜ì„¸ìš”")
        
        # API Key ì²´í¬
        if not st.session_state.api_configured and not get_config_val("api_keys", "google_api_key", "GOOGLE_API_KEY", ""):
            st.warning("âš ï¸ **API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.** ìš°ì¸¡ ìƒë‹¨ì˜ **ğŸ” API ì„¤ì •** ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            st.info("ğŸ’¡ API KeyëŠ” [Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ ë¬¼ë¡  ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # Sidebar configuration for Tab 1
        with st.sidebar:
            st.title("âš™ï¸ ìƒì„± ì„¤ì •")
            
            exp_mode = st.selectbox(
                "íŒŒì´í”„ë¼ì¸ ëª¨ë“œ",
                ["demo_planner_critic", "demo_full"],
                index=0,
                key="tab1_exp_mode",
                help="ì‚¬ìš©í•  ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ì„ ì„ íƒí•˜ì„¸ìš”"
            )
            
            mode_info = {
                "demo_planner_critic": "ê¸°íšì â†’ ì‹œê°í™”ì â†’ í‰ê°€ì â†’ ì‹œê°í™”ì",
                "demo_full": "ê²€ìƒ‰ì â†’ ê¸°íšì â†’ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ â†’ ì‹œê°í™”ì â†’ í‰ê°€ì â†’ ì‹œê°í™”ì. (ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ê°€ ë¯¸ì ìœ¼ë¡œ ë” ì˜ˆìœ ë‹¤ì´ì–´ê·¸ë¨ì„ ë§Œë“¤ì§€ë§Œ ê³¼ë„í•˜ê²Œ ë‹¨ìˆœí™”ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë‘ ëª¨ë“œë¥¼ ëª¨ë‘ ì‹œë„í•˜ì—¬ ë” ë‚˜ì€ ê²ƒì„ ì„ íƒí•˜ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤)"
            }
            st.info(f"**íŒŒì´í”„ë¼ì¸:** {mode_info[exp_mode]}")
            
            retrieval_setting = st.selectbox(
                "ê²€ìƒ‰ ì„¤ì •",
                ["auto", "manual", "random", "none"],
                index=0,
                key="tab1_retrieval_setting",
                help="ì°¸ì¡° ë‹¤ì´ì–´ê·¸ë¨ì„ ê²€ìƒ‰í•˜ëŠ” ë°©ë²•: auto (ìë™ ì„ íƒ), manual (ì§€ì •ëœ ì°¸ì¡° ì‚¬ìš©), random (ë¬´ì‘ìœ„ ì„ íƒ), none (ê²€ìƒ‰ ì—†ìŒ)"
            )
            
            num_candidates = st.number_input(
                "í›„ë³´ ê°œìˆ˜",
                min_value=1,
                max_value=20,
                value=10,
                key="tab1_num_candidates",
                help="ë³‘ë ¬ë¡œ ìƒì„±í•  í›„ë³´ì˜ ìˆ˜"
            )
            
            aspect_ratio = st.selectbox(
                "í™”ë©´ ë¹„ìœ¨",
                ["21:9", "16:9", "3:2"],
                key="tab1_aspect_ratio",
                help="ìƒì„±ë  ë‹¤ì´ì–´ê·¸ë¨ì˜ í™”ë©´ ë¹„ìœ¨"
            )
            
            max_critic_rounds = st.number_input(
                "ìµœëŒ€ í‰ê°€ì ë¼ìš´ë“œ",
                min_value=1,
                max_value=5,
                value=3,
                key="tab1_max_critic_rounds",
                help="í‰ê°€ì ê°œì„  ë°˜ë³µì˜ ìµœëŒ€ íšŸìˆ˜"
            )
            
            default_model = get_config_val("defaults", "model_name", "MODEL_NAME", "YOUR_MODEL_NAME_HERE")
            options = ["", default_model] if default_model else ["", "YOUR_MODEL_NAME_HERE"]
            
            model_name = st.selectbox(
                "ëª¨ë¸ ì´ë¦„",
                options,
                index=0,
                key="tab1_model_name",
                help="ì¶”ë¡ ì— ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„"
            )
        
        st.divider()
        
        # Input section
        st.markdown("## ğŸ“ ì…ë ¥")
        
        # Example content
        example_method = r"""## Methodology: The PaperVizAgent Framework
        
        In this section, we present the architecture of PaperVizAgent, a reference-driven agentic framework for automated academic illustration. As illustrated in Figure \ref{fig:methodology_diagram}, PaperVizAgent orchestrates a collaborative team of five specialized agentsâ€”Retriever, Planner, Stylist, Visualizer, and Criticâ€”to transform raw scientific content into publication-quality diagrams and plots. (See Appendix \ref{app_sec:agent_prompts} for prompts)

### Retriever Agent

Given the source context $S$ and the communicative intent $C$, the Retriever Agent identifies $N$ most relevant examples $\mathcal{E} = \{E_n\}_{n=1}^{N} \subset \mathcal{R}$ from the fixed reference set $\mathcal{R}$ to guide the downstream agents. As defined in Section \ref{sec:task_formulation}, each example $E_i \in \mathcal{R}$ is a triplet $(S_i, C_i, I_i)$.
To leverage the reasoning capabilities of VLMs, we adopt a generative retrieval approach where the VLM performs selection over candidate metadata:
$$
\mathcal{E} = \text{VLM}_{\text{Ret}} \left( S, C, \{ (S_i, C_i) \}_{E_i \in \mathcal{R}} \right)
$$
Specifically, the VLM is instructed to rank candidates by matching both research domain (e.g., Agent & Reasoning) and diagram type (e.g., pipeline, architecture), with visual structure being prioritized over topic similarity. By explicitly reasoned selection of reference illustrations $I_i$ whose corresponding contexts $(S_i, C_i)$ best match the current requirements, the Retriever provides a concrete foundation for both structural logic and visual style.

### Planner Agent

The Planner Agent serves as the cognitive core of the system. It takes the source context $S$, communicative intent $C$, and retrieved examples $\mathcal{E}$ as inputs. By performing in-context learning from the demonstrations in $\mathcal{E}$, the Planner translates the unstructured or structured data in $S$ into a comprehensive and detailed textual description $P$ of the target illustration:
$$
P = \text{VLM}_{\text{plan}}(S, C, \{ (S_i, C_i, I_i) \}_{E_i \in \mathcal{E}})
$$

### Stylist Agent

To ensure the output adheres to the aesthetic standards of modern academic manuscripts, the Stylist Agent acts as a design consultant.
A primary challenge lies in defining a comprehensive â€œacademic style,â€ as manual definitions are often incomplete.
To address this, the Stylist traverses the entire reference collection $\mathcal{R}$ to automatically synthesize an *Aesthetic Guideline* $\mathcal{G}$ covering key dimensions such as color palette, shapes and containers, lines and arrows, layout and composition, and typography and icons (see Appendix \ref{app_sec:auto_summarized_style_guide} for the summarized guideline and implementation details). Armed with this guideline, the Stylist refines each initial description $P$ into a stylistically optimized version $P^*$:
$$
P^* = \text{VLM}_{\text{style}}(P, \mathcal{G})
$$
This ensures that the final illustration is not only accurate but also visually professional.

### Visualizer Agent

After receiving the stylistically optimized description $P^*$, the Visualizer Agent collaborates with the Critic Agent to render academic illustrations and iteratively refine their quality. The Visualizer Agent leverages an image generation model to transform textual descriptions into visual output. In each iteration $t$, given a description $P_t$, the Visualizer generates:
$$
I_t = \text{Image-Gen}(P_t)
$$
where the initial description $P_0$ is set to $P^*$.

### Critic Agent

The Critic Agent forms a closed-loop refinement mechanism with the Visualizer by closely examining the generated image $I_t$ and providing refined description $P_{t+1}$ to the Visualizer. Upon receiving the generated image $I_t$ at iteration $t$, the Critic inspects it against the original source context $(S, C)$ to identify factual misalignments, visual glitches, or areas for improvement. It then provides targeted feedback and produces a refined description $P_{t+1}$ that addresses the identified issues:
$$
P_{t+1} = \text{VLM}_{\text{critic}}(I_t, S, C, P_t)
$$
This revised description is then fed back to the Visualizer for regeneration. The Visualizer-Critic loop iterates for $T=3$ rounds, with the final output being $I = I_T$. This iterative refinement process ensures that the final illustration meets the high standards required for academic dissemination.

### Extension to Statistical Plots

The framework extends to statistical plots by adjusting the Visualizer and Critic agents. For numerical precision, the Visualizer converts the description $P_t$ into executable Python Matplotlib code: $I_t = \text{VLM}_{\text{code}}(P_t)$. The Critic evaluates the rendered plot and generates a refined description $P_{t+1}$ addressing inaccuracies or imperfections: $P_{t+1} = \text{VLM}_{\text{critic}}(I_t, S, C, P_t)$. The same $T=3$ round iterative refinement process applies. While we prioritize this code-based approach for accuracy, we also explore direct image generation in Section \ref{sec:discussion}. See Appendix \ref{app_sec:plot_agent_prompt} for adjusted prompts."""

        example_caption = "Figure 1: Overview of our PaperVizAgent framework. Given the source context and communicative intent, we first apply a Linear Planning Phase to retrieve relevant reference examples and synthesize a stylistically optimized description. We then use an Iterative Refinement Loop (consisting of Visualizer and Critic agents) to transform the description into visual output and conduct multi-round refinements to produce the final academic illustration."
        
        col_input1, col_input2 = st.columns([3, 2])
        
        with col_input1:
            # Example selector for method content
            method_example = st.selectbox(
                "ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸° (ë°©ë²•ë¡ )",
                ["ì—†ìŒ", "PaperVizAgent í”„ë ˆì„ì›Œí¬"],
                key="method_example_selector"
            )
            
            # Set value based on example selection or session state
            if method_example == "PaperVizAgent í”„ë ˆì„ì›Œí¬":
                method_value = example_method
            else:
                method_value = st.session_state.get("method_content", "")
            
            method_content = st.text_area(
                "ë°©ë²•ë¡  ì„¹ì…˜ ë‚´ìš© (Markdown ê¶Œì¥)",
                value=method_value,
                height=250,
                placeholder="ë°©ë²•ë¡  ì„¹ì…˜ ë‚´ìš©ì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...",
                help="ë…¼ë¬¸ì˜ ë°©ë²•ë¡  ì„¹ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”. Markdown í˜•ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
        
        with col_input2:
            # Example selector for caption
            caption_example = st.selectbox(
                "ì˜ˆì‹œ ë¶ˆëŸ¬ì˜¤ê¸° (ìº¡ì…˜)",
                ["ì—†ìŒ", "PaperVizAgent í”„ë ˆì„ì›Œí¬"],
                key="caption_example_selector"
            )
            
            # Set value based on example selection or session state
            if caption_example == "PaperVizAgent í”„ë ˆì„ì›Œí¬":
                caption_value = example_caption
            else:
                caption_value = st.session_state.get("caption", "")
            
            caption = st.text_area(
                "ê·¸ë¦¼ ìº¡ì…˜ (Markdown ê¶Œì¥)",
                value=caption_value,
                height=250,
                placeholder="ê·¸ë¦¼ ìº¡ì…˜ì„ ì…ë ¥í•˜ì„¸ìš”...",
                help="ìƒì„±í•  ê·¸ë¦¼ì˜ ìº¡ì…˜ ë˜ëŠ” ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”. Markdown í˜•ì‹ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            )
        
        # Process button
        if st.button("ğŸš€ í›„ë³´ ìƒì„±", type="primary", use_container_width=True):
            # API Key ì²´í¬
            if not st.session_state.api_configured and not get_config_val("api_keys", "google_api_key", "GOOGLE_API_KEY", ""):
                st.error("âš ï¸ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìš°ì¸¡ ìƒë‹¨ì˜ **ğŸ” API ì„¤ì •** ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            elif not method_content or not caption:
                st.error("ë°©ë²•ë¡  ë‚´ìš©ê³¼ ìº¡ì…˜ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            else:
                # Save to session state
                st.session_state["method_content"] = method_content
                st.session_state["caption"] = caption
                
                with st.spinner(f"{num_candidates}ê°œ í›„ë³´ë¥¼ ë³‘ë ¬ë¡œ ìƒì„± ì¤‘... ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                    # Create input data list
                    input_data_list = create_sample_inputs(
                        method_content=method_content,
                        caption=caption,
                        aspect_ratio=aspect_ratio,
                        num_copies=num_candidates,
                        max_critic_rounds=max_critic_rounds
                    )
                    
                    # Process in parallel
                    try:
                        results = asyncio.run(process_parallel_candidates(
                            input_data_list, 
                            exp_mode=exp_mode, 
                            retrieval_setting=retrieval_setting,
                            model_name=model_name
                        ))
                        st.session_state["results"] = results
                        st.session_state["exp_mode"] = exp_mode
                        timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        st.session_state["timestamp"] = timestamp_str
                        
                        # Save results to JSON file
                        try:
                            # Create results directory if it doesn't exist
                            results_dir = Path(__file__).parent / "results" / "demo"
                            results_dir.mkdir(parents=True, exist_ok=True)
                            
                            # Generate filename with timestamp
                            json_filename = results_dir / f"demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
                            
                            # Save to JSON with proper encoding handling (like main.py)
                            with open(json_filename, "w", encoding="utf-8", errors="surrogateescape") as f:
                                json_string = json.dumps(results, ensure_ascii=False, indent=4)
                                # Clean invalid UTF-8 characters
                                json_string = json_string.encode("utf-8", "ignore").decode("utf-8")
                                f.write(json_string)
                            
                            st.session_state["json_file"] = str(json_filename)
                            st.success(f"âœ… {len(results)}ê°œ í›„ë³´ ìƒì„± ì™„ë£Œ!")
                            st.info(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: `{json_filename.name}`")
                        except Exception as e:
                            st.warning(f"âš ï¸ {len(results)}ê°œ í›„ë³´ëŠ” ìƒì„±ë˜ì—ˆì§€ë§Œ JSON ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                    except Exception as e:
                        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        import traceback
                        st.code(traceback.format_exc())
        
        # Display results
        if "results" in st.session_state and st.session_state["results"]:
            results = st.session_state["results"]
            current_mode = st.session_state.get("exp_mode", exp_mode)
            timestamp = st.session_state.get("timestamp", "N/A")
            
            st.divider()
            st.markdown("## ğŸ¨ ìƒì„±ëœ í›„ë³´")
            st.caption(f"ìƒì„± ì‹œê°„: {timestamp} | íŒŒì´í”„ë¼ì¸: {mode_info.get(current_mode, current_mode)}")
            
            # Show JSON file download if available
            if "json_file" in st.session_state:
                json_file_path = Path(st.session_state["json_file"])
                if json_file_path.exists():
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.info(f"ğŸ“„ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: `{json_file_path.relative_to(Path.cwd())}`")
                    with col2:
                        with open(json_file_path, "r", encoding="utf-8") as f:
                            json_data = f.read()
                        st.download_button(
                            label="â¬‡ï¸ JSON ë‹¤ìš´ë¡œë“œ",
                            data=json_data,
                            file_name=json_file_path.name,
                            mime="application/json",
                            use_container_width=True
                        )
            
            # Display results in a grid (3 columns)
            num_cols = 3
            num_results = len(results)
            
            for row_start in range(0, num_results, num_cols):
                cols = st.columns(num_cols)
                for col_idx in range(num_cols):
                    result_idx = row_start + col_idx
                    if result_idx < num_results:
                        with cols[col_idx]:
                            display_candidate_result(results[result_idx], result_idx, current_mode)
            
            # Add ZIP download button
            st.divider()
            st.markdown("### ğŸ’¾ ì¼ê´„ ë‹¤ìš´ë¡œë“œ")
            
            try:
                import zipfile
                
                zip_buffer = BytesIO()
                with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zip_file:
                    task_name = "diagram"
                    
                    for candidate_id, result in enumerate(results):
                        
                        # Find the final image key (same logic as display)
                        final_image_key = None
                        
                        # Try to find the last critic round
                        for round_idx in range(3, -1, -1):
                            image_key = f"target_{task_name}_critic_desc{round_idx}_base64_jpg"
                            if image_key in result and result[image_key]:
                                final_image_key = image_key
                                break
                        
                        # Fallback if no critic rounds completed
                        if not final_image_key:
                            if current_mode == "demo_full":
                                final_image_key = f"target_{task_name}_stylist_desc0_base64_jpg"
                            else:
                                final_image_key = f"target_{task_name}_desc0_base64_jpg"
                        
                        if final_image_key and final_image_key in result:
                            img = base64_to_image(result[final_image_key])
                            if img:
                                img_buffer = BytesIO()
                                img.save(img_buffer, format="PNG")
                                zip_file.writestr(
                                    f"candidate_{candidate_id}.png",
                                    img_buffer.getvalue()
                                )
                
                zip_buffer.seek(0)
                st.download_button(
                    label="â¬‡ï¸ ZIP ë‹¤ìš´ë¡œë“œ",
                    data=zip_buffer.getvalue(),
                    file_name=f"papervizagent_candidates_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                    mime="application/zip",
                    use_container_width=True
                )
                st.success("ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"ZIP íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # ==================== TAB 2: Refine Image ====================
    with tab2:
        st.markdown("### ë‹¤ì´ì–´ê·¸ë¨ì„ ê³ í•´ìƒë„(2K/4K)ë¡œ ê°œì„  ë° í™•ëŒ€")
        st.caption("í›„ë³´ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ì´ì–´ê·¸ë¨ì„ ì—…ë¡œë“œí•˜ê³ , ë³€ê²½ ì‚¬í•­ì„ ì„¤ëª…í•œ í›„ ê³ í•´ìƒë„ ë²„ì „ì„ ìƒì„±í•˜ì„¸ìš”")
        
        # Sidebar for refinement settings
        with st.sidebar:
            st.title("âœ¨ ê°œì„  ì„¤ì •")
            
            refine_resolution = st.selectbox(
                "ëª©í‘œ í•´ìƒë„",
                ["2K", "4K"],
                index=0,
                key="refine_resolution",
                help="í•´ìƒë„ê°€ ë†’ì„ìˆ˜ë¡ ì‹œê°„ì´ ë” ê±¸ë¦¬ì§€ë§Œ ë” ë‚˜ì€ í’ˆì§ˆì„ ì œê³µí•©ë‹ˆë‹¤"
            )
            
            refine_aspect_ratio = st.selectbox(
                "ì¢…íš¡ë¹„",
                ["21:9", "16:9", "3:2"],
                index=0,
                key="refine_aspect_ratio",
                help="ê°œì„ ëœ ì´ë¯¸ì§€ì˜ ì¢…íš¡ë¹„"
            )
        
        st.divider()
        
        # Upload section
        st.markdown("## ğŸ“¤ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ",
            type=["png", "jpg", "jpeg"],
            help="ê°œì„ í•  ë‹¤ì´ì–´ê·¸ë¨ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        
        if uploaded_file is not None:
            # Display uploaded image
            uploaded_image = Image.open(uploaded_file)
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ì›ë³¸ ì´ë¯¸ì§€")
                st.image(uploaded_image, use_container_width=True)
            
            with col2:
                st.markdown("### í¸ì§‘ ì§€ì¹¨")
                edit_prompt = st.text_area(
                    "ì›í•˜ëŠ” ë³€ê²½ ì‚¬í•­ ì„¤ëª…",
                    height=200,
                    placeholder="ì˜ˆ: 'ìƒ‰ìƒ êµ¬ì„±í‘œë¥¼ í•™ìˆ  ë…¼ë¬¸ ìŠ¤íƒ€ì¼ì— ë§ê²Œ ë³€ê²½' ë˜ëŠ” 'í…ìŠ¤íŠ¸ë¥¼ ë” í¬ê³  êµµê²Œ ë§Œë“¤ê¸°' ë˜ëŠ” 'ëª¨ë“  ê²ƒì„ ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ ë” ë†’ì€ í•´ìƒë„ë¡œ ì¶œë ¥'",
                    help="ë³€ê²½í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì„¤ëª…í•˜ê±°ë‚˜ 'ëª¨ë“  ê²ƒì„ ê·¸ëŒ€ë¡œ ìœ ì§€'ë¥¼ ì‚¬ìš©í•˜ì—¬ í™•ëŒ€ë§Œ í•˜ì„¸ìš”",
                    key="edit_prompt"
                )
                
                if st.button("âœ¨ ì´ë¯¸ì§€ ê°œì„ ", type="primary", use_container_width=True):
                    if not edit_prompt:
                        st.error("í¸ì§‘ ì§€ì¹¨ì„ ì œê³µí•´ì£¼ì„¸ìš”!")
                    else:
                        with st.spinner(f"{refine_resolution} í•´ìƒë„ë¡œ ì´ë¯¸ì§€ë¥¼ ê°œì„  ì¤‘ì…ë‹ˆë‹¤... ì•½ 1ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                            try:
                                # Convert PIL image to bytes
                                img_byte_arr = BytesIO()
                                # Convert RGBA to RGB if necessary (JPEG doesn't support alpha channel)
                                if uploaded_image.mode == 'RGBA':
                                    uploaded_image = uploaded_image.convert('RGB')
                                uploaded_image.save(img_byte_arr, format='JPEG')
                                image_bytes = img_byte_arr.getvalue()
                                
                                # Call nanoviz API
                                refined_bytes, message = asyncio.run(
                                    refine_image_with_nanoviz(
                                        image_bytes=image_bytes,
                                        edit_prompt=edit_prompt,
                                        aspect_ratio=refine_aspect_ratio,
                                        image_size=refine_resolution
                                    )
                                )
                                
                                if refined_bytes:
                                    st.session_state["refined_image"] = refined_bytes
                                    st.session_state["refine_timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                    st.success(message)
                                    st.rerun()
                                else:
                                    st.error(message)
                            except Exception as e:
                                st.error(f"ê°œì„  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                                import traceback
                                st.code(traceback.format_exc())
            
            # Display refined result if available
            if "refined_image" in st.session_state:
                st.divider()
                st.markdown("## ğŸ¨ ê°œì„ ëœ ê²°ê³¼")
                st.caption(f"ìƒì„± ì‹œê°„: {st.session_state.get('refine_timestamp', 'N/A')} | í•´ìƒë„: {refine_resolution}")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### ì´ì „")
                    st.image(uploaded_image, use_container_width=True)
                
                with col2:
                    st.markdown(f"### ì´í›„ ({refine_resolution})")
                    refined_image = Image.open(BytesIO(st.session_state["refined_image"]))
                    st.image(refined_image, use_container_width=True)
                    
                    # Download button
                    st.download_button(
                        label=f"â¬‡ï¸ {refine_resolution} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                        data=st.session_state["refined_image"],
                        file_name=f"refined_{refine_resolution}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                        mime="image/png",
                        use_container_width=True
                    )

if __name__ == "__main__":
    main()
